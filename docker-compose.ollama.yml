version: '3.8'

services:
  deepwiki-ollama:
    build:
      context: .
      dockerfile: Dockerfile-ollama-local
      args:
        TARGETARCH: amd64  # Change to arm64 if on ARM architecture
    network_mode: host  # Use host networking for direct access to Ollama
    env_file:
      - .env
    environment:
      - PORT=${PORT:-8001}
      - NODE_ENV=production
      - SERVER_BASE_URL=http://localhost:${PORT:-8001}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FILE_PATH=${LOG_FILE_PATH:-api/logs/application.log}
      - OLLAMA_HOST=http://localhost:11434  # Direct localhost access with host networking
    volumes:
      - ~/.adalflow:/root/.adalflow      # Persist repository and embedding data
      - ./api/logs:/app/api/logs          # Persist log files across container restarts
      - ../BHT:/app/local-repos/BHT       # Mount BHT repository for analysis
    # Override the default command to bypass API key checks
    command: >
      bash -c "
        ollama serve > /dev/null 2>&1 &
        sleep 10 &&
        python -m api.main --port 8001 &
        PORT=3000 HOSTNAME=0.0.0.0 node server.js
      "
    # Resource limits for docker-compose up (not Swarm mode)
    mem_limit: 6g
    mem_reservation: 2g
    # Health check configuration
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${PORT:-8001}/health"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s
